## 相关概念 

### carriy dependency

携带依赖

同一线程内, 若 evaluation A **sequenced-before** evaluation B, 则 **A carry dependency into B**:

* A 的 value 用作 B 的操作数

  > 除非 A 是内置 `&&` `||` `?:` `,` 的**左操作数**
  >
  > 除非 B 是 kill_dependency()

* A 向标量对象 M **write**, B 从 M **read** 
* **A carry dependency into evaluation X** 且 **X carry dependency into B**

### release sequence

对原子对象 M 执行 **release** 操作 A 后, M 上 **modification order** 的**最长连续子序列**包含:

* A 所在线程的执行的 **write**
* 任何线程在 M 上的 **atomic read-modify-write**

被称为 **A 开头的 release sequence**

### synchronize with

若线程 A 中的 **atomic store** 是 **release** 操作, 线程 B 中在同一变量上的 **atomic load** 是 **acquire** 操作

且 B 中的 **load** 读到的值来自于 A 中的 **store**, 则 A 中的 **store synchronize-with** B 中的 load

### dependency-ordered before

线程间, evaluation A **dependency-ordered before** evaluation B:

* A 在原子对象 M 执行一个 **release** 操作, 在另一线程中 B 对 M 执行一个 **consume** 操作

  并且 B 读到的值来自 **A 开头的 release sequence**

*  **A dependency-ordered before X** 且 **X carry dependency into B**

#### inter-thread happen-before

线程间, evaluation A **inter-thread happen before** evaluation B:

* A **synchronize with** B
* A **synchronize with** X 且 X **sequence before** B
* A **dependency-ordered before** B
* A **sequence before** X 且 X **inter-thread happen-before** B
* A **inter-thread happen-before** X 且 X **inter-thread happen-before** B

### happen-before

无论是线程内还是线程间, evaluation A **happen before** evaluation B:

* A **sequence before** B
* A **sequence before** B

如果某个 evaluation 修改了 memory location, 另一 evaluation 访问了该 memory location

且至少有一个不是原子操作, 则会产生**未定义行为**, 除非两者有 **happen-before** 关系

# 同步操作和强制次序

**synchronizing operation** 和 **enforcing order**

### 非原子操作问题

在同一 memory location 上进行**非原子读写操作**会造成**未定义行为**

* 一方面有指令级的并发
* 一方面非原子操作会被**编译器或处理器**进行**指令重排**, 可能造成预期之外的结果
  * 编译器会将 **atomic load** 和 **atomic store** 视为 **memory fence** 内存栅栏, 并且**进行指令重排时不会越过这个内存栅栏**

```C++
#include <iostream>
#include <thread>
#include <atomic>

using namespace std;

//atomic<int> x{ 0 };
int x = 0;

void func()
{
    for (int i = 0; i < 100000; i++)
    {
        x++;
    }
}

int main()
{
    thread t1(func);
    thread t2(func);
    t1.join();
    t2.join();

    cout << x << endl;

    return 0;
}
```

最终的结果一般在 100000 ~ 200000 之间, 原因是**指令级的并发**

```C++
x++ 一般分为三个指令
    
memory x -> register r
r++
register r -> memory x
```

### 场景

两个线程, 一个生产数据, 一个读数据

为了避免条件竞争, 使用 **flag** 表示数据已准备好, 读线程等 `flag == true` 成立才读取数据

```C++
vector<int> arr;
atomic<bool> flag(false);

void write()
{
    arr.push_back(1);		a1
    flag = true;			a2
}

void read()
{
    while(!flag.load())		b1
        sleep();
    cout << arr[0] << endl;	b2
}
```

这段代码中: 

非原子的读写操作所需的**强制排序** **enforcing order** 来自 `atomic<bool> flag` 上的操作

因子这些原子操作提供了 **happen-before** 和 **synchronize-with** 内存模型关系(**memory model relation**)

> 具体来说, 原子对象 flag 上的操作作为内存栅栏/内存屏障, 使得编译器或处理器进行指令重排时不会越过该内存栅栏

数据的 write 操作 a1 **happen-before** flag 的 write 操作 a2

> 即 a1 永远在 a2 前面执行 	a1 < a2

flag 的 read 操作 b1 **happen-before** 数据的 read 操作

> 即 b1 永远在 b2 前面执行 	b1 < b2

当 flag 变为 true 时, 数据的 write 操作就 **synchronize-with** 数据的 read 操作, 构成了 **happen-before** 关系

$~$

write **happen-before** read 推导过程如下: 

当 write synchronize-with read 时, 构成了 happen-before 关系

即 write 永远在 read 前面执行, write < read	a1 < b2

推导过程为:

a1 happen-before a2, 则 a1 < a2

b1 happen-before b2, 则 b1 < b2

而只有当 a2 执行完后, b1 才会执行, 即构成 a2 happen-before b1 关系, a2 < b1

由于 happen-before 关系可传递

由上面知:

a1 happen-before a2

a2 happen-before b1

b1 happen-before b2

所以 a1 和 b2 构成 happen-before 关系, a1 < b2

总的来说 a1 < a2 < b1 < b2, 最终利用**原子操作**强制**非原子操作**遵从了某种次序

$~$

根据上述分析, 最终得到了 **enforced ordering**:  write of data **happen-before** read of data

下列展示这一过程中的几个 happen-before 关系:

```C++
write:					read:
{						{
    arr.push_back(1)		flag.load() 	返回 false
    flag = true				flag.load()		返回 false
        					flag.load()		返回 true
        					arr[0]			返回 1
}						}
```

![](.\image\happen-before.png)

### synchronize-with 关系

**synchronize-with** 关系只存在于**原子类型上的操作**间

如数据结构(原子类型成员)上的原子操作可能展现出这种**同步关系**

但本质上 **synchronize-with** 关系来源于**原子类型上的操作**

**作用**:

在变量 x 上, 适当 **memory order** 修饰的 **atomic write** 操作(记为 W)  **synchronize-with** 适当 **memory order** 修饰的 **atomic read** 操作:

* read 操作读到 W 写入的值
* read 操作读到 W 所在线程中在 W 之后的对 x 的 **atomic write** 写入的值
* read 操作读到**任意线程**作用在 x 上的 **atomic read-modify-write** 操作 **sequence**(序列)所写入的值, 此 **sequence** 的第一个 **read** 读到的值是 W 写入的值

**示例**:

```C++
shared variable x;

A:				B:				
{				{
    				x.CAS();		cas0
    x.write(1);						w1 == W
                    x.write(2);		w2
    				x.CAS();		cas1
    x.write(3);						w3
    x.CAS();						cas2
                    x.CAS();		cas3
}				}
```

atomic write W **synchronize-with** atomic read R 的含义是:

若 R 在 W 后面执行, 则 R 不可能读到 W 前面 write 操作写入的值

> W 代指 w1 write 操作, R 表示时间上在 W 后执行的 read 操作
>
> 则 R 不可能读到 w0 写入的值

* R 读到 W 写入的值

* R 读到 w3 写入的值

* R 读到 **read-modify-write** sequence `cas1 cas2 cas3` 中的某一个操作写入的值

  注意该序列的第一个 read 操作读到的必须是 W 写入的值

**分析**

**case1**:

R 读到 W 的值, 显然能说明 **W synchronize-with R**, 形成同步关系

**case2:**

R 读到 W 所在线程后续 write 的值, 即示例中 w3 的值

**case3:**

R 读到 **read-modify-write** sequence 中某个操作写入的值, 该序列的第一个读操作读到的是 W 写入的值

示例中该序列为 `cas1 cas2 cas3` 不包括 cas0 是因为其在 W 之前发生

必须是 **read-modify-write** sequence 的原因是要建立**同步关系**, 如果只是单纯的 write 操作(例如 w2), 写入的值跟 W 写入的值没有**相关性**, 自然就谈不上**同步关系**

> 与 W 在同一线程的 write 操作就能与 R 建立同步关系, 因为 x 后续的值对该线程可见

### happen-before 关系

**happen-before** 和 **strongly-happen-before** 关系是**确立操作次序**的基础

作用是**界定**哪些 **operation** 能够看到另一 **operation** 的  **effects**

**线程内**

若 operation A **sequence before** operation B

则 **A happen before B**, 且 **A strongly-happen-before B**

若同一语句有多个操作, 则没有 happen-before 关系, 因为 C++ 没有规定这种顺序, 所以**编译器可以任意重排**

**线程间**

若某一线程内的 operation A **inter-thread happen before** 另一线程的 operation B, 则 A happen before B

## memory order

一共有 6 种 memory order

```C++
enum memory_order 
{
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
};
```

分别代表了 3 种 **memory order model**:

* **sequentially consistent ordering** 顺序一致次序
  * memory_order_seq_cst
* **acquire-release ordering** 获取-释放次序
  * memory_order_consume
  * memory_order_acquire
  * memory_order_release
  * memory_order_acq_rel
* **relaxed ordering** 宽松次序
  * memory_order_relaxed

在不同的 CPU 架构上, 这些 **memory-ordering model** 往往会有不同的 **cost**, 

例如, 在对处理器操作可见性上有良好控制的架构上, 就额外必要的同步指令而言

sequentially consistent ordering > acquire-release ordering > relaxed ordering

如果这些系统上有很多处理器, 那么这些额外必要的同步指令会让整体性能下降

另一方面,  x86 架构, 除了保证原子性之外, 对 acquire-release ordering 不需要额外的同步指令, 

即使是 sequentially consistent ordering 也不需要对 load 操作有额外的处理, 除了对 store 操作有额外的 cost 外

### sequentially consistent ordering

**顺序一致次序**: 将所有的操作视作顺序执行, 就像**多线程的操作在一个线程中执行一样**

所有线程看到相同的 **operation order**

在所有线程能组成的**所有可能操作序列**上, **排除 inconsistent** 的代码后

就是 **sequentially consistent ordering** 允许的序列

顺序一致性次序具有传递性:

同一变量上, 顺序一致 **store** 操作 A **synchronize-with** 顺序一致 **load** 操作 B, 且在 B 后边又执行了别的顺序一致原子操作 C

则在**其他使用 顺序一致原子操作 的线程**看来, C 操作同样在 A 操作后面

这就是**顺序一致模型**中 A **synchronize-with** B, B 早于 C, 于是 A 早于 C 的传递性

但若其他线程服从**宽松次序**, 就依然能看到不同于此的次序

$~$

顺序一次次序

```C++
#include <iostream>
#include <atomic>
#include <thread>
#include <assert.h>

using namespace std;

atomic<bool> x, y;
atomic<int> z;

void write_x()
{
	x.store(true, memory_order_seq_cst);
}

void write_y()
{
	y.store(true, memory_order_seq_cst);
}

void read_x_then_y()
{
	while (!x.load(memory_order_seq_cst));
	if (y.load(memory_order_seq_cst))
		++z;
}

void read_y_then_x()
{
	while (!y.load(memory_order_seq_cst));
	if (x.load(memory_order_seq_cst))
		++z;
}

int main()
{
	x = false;
	y = false;
	z = 0;

	thread a(write_x);
	thread b(write_y);
	thread c(read_x_then_y);
	thread d(read_y_then_x);

	a.join();
	b.join();
	c.join();
	d.join();

	assert(z.load() != 0);
}
```

