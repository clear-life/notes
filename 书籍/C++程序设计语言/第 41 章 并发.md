# 第 41 章 并发

## 引言

**挑战**: 保证多线程并发访问内存的方式合理

STL对并发的支持:

1. **内存模型**: 对体系结构的抽象
2. **无锁编程**: 原子操作
3. **thread**: 锁风格系统级并发编程, 如 thread, condition_variable 和 mutex
4. **task**: 任务级并发编程, 如 future, promise, package_task 和 async()

> 从底层到高层排列, 应尽可能在高层次编程 
>
> CPU的流程为以下五个阶段： 
>
> 取指 （Instruction Fetch） 
>
> 译码 （Decode） 
>
> 执行 （Execution） 
>
> 访存 （Memory Request）  
>
> 写回（Write Back）

## Memory Model

### 内存模型基础

STL 并发组件基于**内存模型**

* 内存模型是**硬件工作者和编译器工作者**之间对**计算机硬件的抽象**
* 内存模型是**编译器工作者和程序员**之间的协议, 使得大多数程序员不必考虑硬件细节

$~$

引理: **永远不会直接在内存中操作对象**, 而是**先加载到处理器寄存器中, 处理过后再写回到内存中**

1. 对象先**从主存加载到缓存**, 再**从缓存加载到寄存器**

2. 处理过后, 先**从寄存器写回到缓存**, 再**从缓存写回到主存**

**内存和缓存都可以被多个线程共享**, 从而导致出问题

```assembly
# x 递增:
load x into Cx		# cache Cx 
load Cx into Rx		# register Rx
Rx = Rx + 1
store Rx into Cx
store Cx into x
```

### Memory Location

**线程访问内存的顺序问题**

两个全部变量 a 和 b, 最终结果正常为 `x == 1 and y == 1`

```C++
char a = 0;
char b = 0;

A:
{
    a = 1;
    int x = a;
}

B:
{
    b = 1;
    int y = b;
}
```

如果链接器将 a 和 b 分配到同一内存 word 中且机器存取的最小单位是 word, 

线程 A 和线程 B 并发执行, 结果可能有多种情况:

> word: 数据总线的大小, 32位机器为32bit, 64位机器为64bit
>
> word = a__b
>
> word 初始为 0__0, a 和 b 的初始化在所有线程启动前由编译器或链接器完成

线程 A:

1. load word
2. modify a
3. store word

线程 B:

1. load word
2. modify b
3. store word

```C++
共 20 种情况
a1  a2  a3  b1  b2  b3  	11
a1  a2  b1  a3  b2  b3  	01
a1  a2  b1  b2  a3  b3      01
a1  a2  b1  b2  b3  a3  	10
a1  b1  a2  a3  b2  b3  	01
a1  b1  a2  b2  a3  b3  	01
a1  b1  a2  b2  b3  a3  	10
a1  b1  b2  a2  a3  b3  	01
a1  b1  b2  a2  b3  a3  	10
a1  b1  b2  b3  a2  a3  	10
b1  a1  a2  a3  b2  b3  	01
b1  a1  a2  b2  a3  b3  	01
b1  a1  a2  b2  b3  a3  	10
b1  a1  b2  a2  a3  b3  	01
b1  a1  b2  a2  b3  a3  	10
b1  a1  b2  b3  a2  a3  	10
b1  b2  a1  a2  a3  b3  	01
b1  b2  a1  a2  b3  a3  	10
b1  b2  a1  b3  a2  a3  	10
b1  b2  b3  a1  a2  a3  	11
```

线程 A 和线程 B 并发执行, 结果一共有 20 种情况,

其中, 2 种情况结果为 `1__1`(正确), 9 种情况结果为 `1__0`(错误),  9 种情况结果为 `0__1`(错误)

> 基于 **sequentially consistent** 的前提

$~$

总结:

C++ **memory model** 保证了两个线程可以**互不影响**地 **update and access** 不同的 **memory location**

C++ 将 **memory location** 定义为能够通过合理行为排除单独位域的 **memory unit**

**a memory location** 可以是**标量类型的对象**, **非零位域的最大相邻序列**

$~$

### Instruction Reordering

为提高性能, **编译器, 优化器和硬件**都可能**重排指令序列**

**场景**:

```C++
int x;
bool flag;

A:
{
    x = 1;			a1
    flag = true;	a2
}

B:
{
    int y;
    while(!flag)	b1
        sleep();	
    y = x;			b2
}
```

**instruction reorder case1**: 无关代码重排

对线程 A, `x = 1` 和 `flag = true` 两段代码的位置可以随意调整, 

编译器, 优化器或硬件可能先执行 `flag = true` 来加速程序

```C++
A:
{
    x = 1;			a1
    flag = true;	a2
}
A 重排后: a2 a1 
```

最终可能的指令序列:

```C++
a2  b1  b2  a1
```

问题: b2 `y = x` 会将未初始化的 x 赋值给 y 

$~$

$~$**instruction reorder case2**: 循环条件外提

即使没有调整指令顺序, 仍有可能遇到问题:

线程 B 种没有 `flag` 的赋值, 优化器可能会将 `!flag` 的求值提到 `while` 循环外, 从而线程 B 要么**永远不睡眠**或**永远睡眠**

```C++
B:
{
    int y;
    while(!flag)	b1
        sleep();	
    y = x;			b2
}

B 重排后:
{
    int y;
    t = !flag;		b1`
    while(t)
        sleep();
    y = x;			b2`
}
```

最终的指令序列:

```C++
a1 a2 b1` b2`			线程 B 永远不 sleep
a1 b1`(sleep) b2` a2	线程 B 永远 sleep
```

问题: 线程 B 永远不 sleep 或永远 sleep

### Memory Order

将一个 word 的值从 memory 加载到 cache, 再到 register, 所花费的时间大概有 500 个指令周期

但却会使得**不同线程**在**不同时间**, **不同 memory 层次** **look at** 同一 **value** 可能会产生**巨大的混乱**

$~$

可能的二级缓存结构:

* **每个 core** 单独一个 **level-2 cache**
* **一对 core** 共享一个 **level-1 cache**
* **所有 core** 共享 **memory**

```C++
    core1        core2        core3        core4
    cache2.1     cache2.2     cache2.3     cache2.4
          cache1.1                  cache1.2
        				memory
```

$~$

**memory order** 指定了对 **atomic operation** **内存访问**的次序

> 内存访问指从 memory 读的过程, 或写回 memory 的过程
>
> 包含 memory-cache-register 的过程

> 非原子内存访问: 在非原子内存访问的过程中, 允许其余线程访问同一 **memory location**
>
> 一次内存访问 = read/write memory-cache-register
>
> 则在非原子 memory-cache 或 cache-register 的过程中, 其余线程能够对同一 memory location 进行内存访问

$~$

**sequentially consistent**: 每个线程看到的都是相同的 **operation order**, 就像所有的指令在一个线程中 **sequentially** 执行一样. 

> 同一线程的原子操作按照 **happens-before** 执行, 不同线程的原子操作执行关系任意. 本质就是按照**代码写的方式**执行, 也就是 dfs 穷举的方式.

在 **sequentially consistent** 内存模型中, 线程仍能进行**指令重排**, 但其余线程看不到中间过程

> **指令重排中 variable 的变化好比不变量被破坏**, 其余线程看不到不变量被破坏的中间状态

**sequentially consistent** 内存模型的例子:

```C++
a = 0
b = 0
    
A:
{
    a = 1;		a1
    int x = b;	a2
}

B:
{
    b = 1;		b1
    int y = a;	b2
}
```

多线程环境下, **instruction order** 有 6 种情况:

```C++
// 6 种 instruction order:
a1  a2  b1  b2  	x == 0, y == 1
a1  b1  a2  b2  	x == 1, y == 1
a1  b1  b2  a2  	x == 1, y == 1
b1  a1  a2  b2  	x == 1, y == 1
b1  a1  b2  a2  	x == 1, y == 1
b1  b2  a1  a2  	x == 1, y == 0
```

结果(指 x 和 y 的值)一共有 3 种情况: 01, 10 和 11

$~$

显然, 为了保证 **sequentially consistent** 内存模型, 需要对**共享内存位置**的访问做某种形式的 **synchronization**

但是同步开销比较大, 约束更小的内存模型可以有更小的同步开销:

比如, 两个线程在 **write** a 和 b **开始前或结束前**执行对 x 和 y 的读取操作, 从而得到 **nonsequentially consistent** 结果 00

```C++
a2 b2 a1 b2		x == 0, y == 0
```

$~$

### Data Race

**data race**: 两个线程同时访问一个 **memory location** 且至少有一个 **write access**, 就有可能发生 **data race**

如 **Instruction Reordering** 示例所示, **data race** 可能由于 **Instruction Reordering** 产生**未定义行为**, 后果很严重.

$~$

避免 **data race** 的方法:

* 单线程
* 使用锁, 或选择性使用锁
* 任务级并发
  * future, shared_future, promise, packaged_task, async
* **higher-level library or tool**

## Memory Order

### lock-free programming

> 无锁编程

**lock-free programming**, 即不显式使用锁, 而是使用 **primitive operation**(**原语**, 硬件直接支持) 来编写并发程序.

**primitive operation** 常称为 **atomic operation**, 可用来实现更高层次**并发机制**, 如 **locks, threads** 和 **lock-free data structures**

* **lock-free programming** 不会出现**死锁**和**饥饿**问题
* **lock-free programming** 保证即使有其他线程**竞争访问原子对象**也能正常推进
* **lock-free programming** 比 **lock-based programming** 速度快

$~$

### synchronization operation

> 同步操作

STL 定义了一些**原子操作**和**在互斥锁上的操作**, 被称为**同步操作**

> 同步操作确保在其发生时, 会在其他任何访问同一 **memory location** 上的操作开始之前完成, 即**原子性**, 用于**同步**多线程对**共享资源**的访问

在**同步操作**之间,  编译器和处理器可以**任意 reorder code**, 并且没有任何线程能够 **look at** 这种重排

> 不变量被破坏的状态其余线程看不到

在 **memory location** 上的 **synchronization** 操作包括:

* **acquire** 操作

  其余 **processors** 会先看到 **acquire** 操作的结果, 再看**后续所有操作**的结果

  * **acquire** < **后面所有操作**

  * 先 **acquire**, 再后面

* **release** 操作

  其余 **processors** 会先看到**前面所有操作**的结果, 再看到  **release** operation 的结果

  * **前面所有操作** < **release**

  * 先前面, 再 **release**

* **consume** 操作

  其余 **processors** 会先看到 **acquire** 操作的结果, 再看**后续所有操作**的结果. 但在**后面操作**不依赖于 **consume** 操作的 **value** 时, 该后面操作有可能 **happen-before** 该 **consume** 操作

  * 弱化的 **acquire** 操作
  * **acquire** < **后面所有操作**, 若后面操作 T 不依赖于 **acquire** 操作时, 有可能 **T < acquire**
  * 先 acquire, 再后面, 但**无依赖关系的可能在前面**

* **acquire and release** 操作

### memory order

原子操作会保证**内存的状态**与 **memory order** 要求的一致

默认情况下, **memory order** 为 **memory_order_seq_cst**, 即**顺序一致性**

**std::memory_order**

```C++
enum memory_order 
{
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
};
```

* **relaxed**: 无要求
* **acquire**, **acq_rel** 和 **seq_cst**: **load** 操作会对 memory location 执行一个 **acquire** 操作
* **consume**: **load** 操作会对 memory location 执行一个 **consume** 操作
* **release**, **acq_rel** 和 **seq_cst**: **store** 操作会对 memory location 执行一个 **release** 操作

考虑使用 atomic **load 和 store** 来展示 **relaxed** memory order:

```C++
A:
{
    r1 = y.load(memory_order_relaxed);	a1
    x.store(r1, memory_order_relaxed);	a2
}

B:
{
    r2 = x.load(memory_order_relaxed);	b1
    y.store(42, memory_order_relaxed);	b2
}
```

 其中, x 和 y 代指内存, r1, r2 代指寄存器

```C++
memory		x		y
    
register	r1		r2

A:
	y 	-> 	r1		a1
    r1	->	x		a2
        
B:
	x	->	r2		b1
    42	-> 	y		b2
```

**relaxed** memory order 对内存访问次序无任何要求, 就指令就会有可能**任意重排**

一种可能的重排, 产生 `r2 == 42` 的结果 

```C++
b2  a1  a2  b2:

{
    42	-> 	y		b2
        
	y 	-> 	r1		a1
    r1	->	x		a2
        
	x	->	r2		b1
    
}

结果: r2 == 42
```

为了优化 **relaxed memory model**, C++ 标准提供了 **[[carries_dependency]]** 属性, 能传递 **memory order**

```C++
[[carries_dependency]] struct A* fun(int i)
{
    ...
    
    // 令调用者对结果使用 memory_order_consume
    return arr[i].load(memory_order_consume);
}
```

还可以将 **[[carries_dependency]]** 作为参数,  用函数 `kill_dependency()` 停止 **memory order** 传递

## atomic Types

 原子类型是 `atomic<>` 的特化

原子类型上的操作是在**简单对象**(通常是一个 **memory location**) 上的 **load and store**, **swap**, **increment** 等

### atomic<T\>

* x.val 表示源自对象 x 的值
* 所有操作都 **noexcept**

**初始化与赋值**

```C++
atomic x;		// x 未初始化	
atomic x{};		// 默认构造: x.val = T{}; constexpr
atomic x{t};	// 构造函数: x.val = t; constexpr
x = t			// T 类型对象赋值: x.val = t
t = x			// 隐式类型转换为 T 类型: t = x.val 
```

**load, store 和 exchange**

```C++
x.is_lock_free()			// x 是否用 lock-free 实现: 是否用原子指令实现, 还是要借助内部锁来实现
x.store(t)					// x.val = t
x.store(t, order)		
t = x.load()				// t = x.val
t = x.load(order)
t2 = x.exchange(t)			// x->t2 t->x  
t2 = x.exchange(t, order)
```

**compare exchange**

```C++
bool b;		// b = (x.val == rt)
T& rt = ...;

b = x.compare_exchange_weak(rt,t)		
    if x.val == rt
        b = true
        x.val = rt	// 有可能失败了但返回 true
    else
        b = false
        rt = x.val
b = x.compare_exchange_weak(rt,t,o1,o2)	
    if x.val == rt and x.val = t 成功
        b = true
        memory_order = o1;
	else
        b = false
        memory_order = o2;
		rt = x.val
b = x.compare_exchange_weak(rt,t,order)
    
b = x.compare_exchange_strong(rt,t)
    if x.val == rt
        b = true
        x.val = t
    else
        b = false
        rt = x.val
b = x.compare_exchange_strong(rt,t,o1,o2)
b = x.compare_exchange_strong(rt,t,order)
```

* `atomic` 没有**拷贝和移动**操作
* `atomic` 的初始化不是原子操作

**共享计数的实现**

```C++
template<typename T>
class shared_ptr
{
public:
	shared_ptr() p(nullptr), *pcnt(0) {}
    ~shared_ptr()
    {
        if(--*pcnt)
            delete p;
    }
private:
    T* p;
    atomic<int>* pcnt;
}
```

### CAS

**strong 与 weak 的区别**

`compare_exchange_strong()` 和 `compare_exchange_weak()` 的区别在于 weak 版本允许因硬件的某些原因而**失败**

> `x.compare_exchange_weak(rt, t)`
>
> 失败指即使 `x == rt` 成立, `x = t` 的操作依然失败

**向原子对象有条件地赋值的问题**:

假定现在要对源自对象 x 执行一个翻倍操作

但翻倍操作需要**"瞬间"**执行, 在翻倍操作执行期间, **不变量被破坏**, 此时其他线程访问 x 的值就会出问题

```C++
atomic x = 1;

A:					B:
{					{
    rt = x.load()
    					x = 3;
	x.store(2*rt)
}					}
```

若在读取 x 的值后, 线程 B 修改了 x 的值, 则 `2 * t = 2` 会将线程 B 修改的值覆盖, 相当于**在不变量被破坏的时候让其余线程访问到共享变量**

经典的 **compare-and-swap** 循环

使用 CAS 原子操作配合循环可以解决上述问题  

```C++
atomic<int> x = 0;
...
int rt = x.load();		rt = x.load()
do
{
    int t = fun(rt);	t = 2 * rt
}while(!x.compare_exchange_weak(rt, t));	
// 判断不变量被破坏期间有没有被访问过
如果没有
    x.store(2*rt)
如果有
    更新 rt, 重新计算并判断, 直到不变量被破坏期间没有被访问过为止 
```

`while` 循环的目的是**基于 x 的当前值写入计算后的值**

假定 fun 执行的计算为 `2 * rt`

执行 `while` 循环的判断时, 

* 若 `x.val == rt `

  说明 x 的值符合预期, 则可以**将经 fun 计算后的值 t 写入 x**

* 若 `x.val != rt`

  说明 x 的值被修改了, 不符合预期, 于是更新 `rt = x.val` 后重新循环, 

  **最终一定要将 x 的值变为 fun "瞬间"计算后的值**

$~$

**CAS 操作的 ABA 问题**

`compare_exchange_strong()` 这类操作常被称为 **compare-and-swap** 操作

CAS 操作都有一个严重的问题, 即 **ABA 问题**

ABA 问题的三个条件:

* 线程两次读取同一 **memory location** 的值, 用**两次的值是否相等**来判断 **memory location 的值是否变化过**
* **memory location** 是共享变量, 且存在**"值回退"**的可能
* **读取间隔没有采用同步手段**, 如上锁

**通用场景**:

```C++
memory location x = A;

A:							B:
{							{
    rt = x;		// 第一次读取 rt == A
    ...							x = B;
    							x = A;
							}
    if(x.compare_exchange_weak(rt, t));	// 第二次读取并比较 x == rt
    	...		// 发现两次的值相等, 于是认为 x 没有变化过, 采取某种措施
}
```

**问题场景**:

有一单链表 head, 根据 x 和 head->val 的大小关系, 决定是否插入新节点 nh 

```C++
atomic<node*> head;

A:
{
    node* nh = new node(x, nullptr);
    node* h = head.load();
    
    do
    {
        if(x > h->val)
            break;
        nh->next = h;		// h 代表线程看到的 head 值
    }while(!head.compare_exchange_weak(h, nh));
}
```

问题的本质: 根据 **head 的值是否变化**来判断**head 节点是否变化过**

但 head 的值可能经过 A-B-A 的变化过程, 尽管两次的 head 值相等, 但关键的节点 val 却有可能变化

```C++
atomic<node*> head = A;		// A->val = 3
							// 链表 A -> B -> C
{
    node* nh = new node(1, nullptr);
    node* h = head.load();	// h == A
    
    do
    {
        if(1 > h->val)		
            break;
        					// 1 < 3, 满足插入条件
        					head = B;
        					head = A;	// A->val 变为 0, 不满足插入条件 
        nh->next = h;		// 插入操作
    }while(!head.compare_exchange_weak(h, nh));	// head == h 判定通过, 但 head->val 却发生了变化
    // 在不满足插入条件的情况下完成了插入操作
}
```

$~$

### atomic 整数

**算术运算与位运算**

```C++
atomic<T> x;
T z;		// z 存储 x 的旧值

z = x.fetch_add(y)			// x.val += y
z = x.fetch_add(y,order)	
z = x.fetch_sub(y) 			// x.val -= y
z = x.fetch_sub(y,order)
z = x.fetch_and(y)			// x.val &= y
z = x.fetch_and(y,order)
z = x.fetch_or(y)			// x.val |= y
z = x.fetch_or(y,order)
z = x.fetch_xor(y)			// x.val ^= y
z = x.fetch_xory,order)
```

**运算符**

```C++
++x 		// 返回新值
x++ 		// 返回旧值
--x 		// 返回新值
x-- 		// 返回旧值

// 返回新值
x += y 		
x -= y 
x &= y 
x |= y 
x ^= y
```

### atomic 指针

```C++
atomic<T*> x;
T* z;	// z 存储旧值

z = x.fetch_add(y)		// x.val += y
z = x.fetch_add(y,order)
z = x.fetch_sub(y)		// x.val -= y
z = x.fetch_sub(y,order)
    
++x 	// 返回新值
x++ 	// 返回旧值
--x 	// 返回新值
x-- 	// 返回旧值
x += y 	// 返回新值
x -= y	// 返回新值
```



### double-checked locking

**双重检查锁**范型

问题: 初始化变量时需要使用锁, 为避免每次访问变量时都要经过锁的范围, 使用双重检查锁范型

通过原子类型来实现

```C++
mutex m;
atomic<bool> flag(flase);

void fun()
{
    if(!flag)
    {
        m.lock();
        if(!flag)
        {
            init();		// 原子类型可防止指令重排将 init() 外提
            flag = true;	
        }
        m.unlock();
    }
}
```

双重检查锁范型还能通过 STL `once_flag` 和 `call_once()` 来代替

### atomic_flag 和 fence

**原子标志和栅栏**是**更低层次的同步特性**

* 主要用于实现**最底层的原子特性**, 如**自旋锁**和 **atomic<>**
* C++ 在**任何情况下**都能保证**原子标志和栅栏**以 **lock-free 机制**实现

**atomic_flag**

* atomic_flag 是最简单最底层的原子类型
* 任何操作都能保证是硬件层面的原子操作
* 其他原子类型都能用 atomic_flag 来实现

atomic_flag 有两种值, **set** 和 **clear**

```C++
// 任何原子操作都是 noexcept

atomic_flag f;		// f 的值未定义
atomic_flag f{};	// 默认构造, f == 0
atomic_flag f{ATOMIC_FLAG_INIT};// f 初始化为 clear
b = f.test_and_set()// set f 且 b 为 f 的旧值
b = f.test_and_set(order)
    
f.clear()			// clear f
f.clear(order)
```

用 `{}` 初始化 `atomic_flag` 看起来合理, 但 0 不一定表示 clear, 可能存在 1 表示 clear 的机器

应该用 `ATOMIC_FLAG_INIT` 初始化 `atomic_flag`

用 `atomic_flag` 实现自旋锁

```C++
class spin_mutex
{
	atomic_flag flag = ATOMIC_FLAG_INIT;    
public:
    void lock()		// flag == 1 表示锁被持有
    {
        // 当 flag 的值为 0 时, 将 flag 置为 1 并返回, 表示当前线程持有了锁
        while(flag.test_and_set());	
    }
    void unlock()
    {
        flag.clear();	// 置 flag 为 0, 表示释放锁
    }
}
```

**fence**

**fence 栅栏**, 也称为 **memory barrier 内存屏障**

是一种根据**指定的 memory order** 来限制**操作重排**的操作, 与 **atomic** 组合使用

```C++
// 所有操作都是 noexcept
atomic_thread_fence(order)		// 强制 memory order 为 order
atomic_signal_fence(order)		// 强制 memory order 为 order
```

## volatile

volatile 用来指定一个对象可被线程外的东西修改

```C++
volatile const long clock_register;	// 通过硬件时钟更新
```

volatile 告知编译器不要优化相关的读写操作

```C++
auto t1{clock_register};
...		// 未使用过 clock_register 
auto t2{clock_register};
```

如果 `clock_register` 没有 volatile 修饰, 编译器就有可能删除一个 `clock_register` 的读操作并假定 `t1 == t2`
